{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNIPPET_DIR_PATH = '/home/unnc/Documents/_data/_snippet/'\n",
    "ORIGIN_DIR_PATH = '/home/unnc/Documents/_data/_original_data/'\n",
    "\n",
    "\n",
    "TRAIN_NAME = f'train'\n",
    "\n",
    "TEST_17_NAME = f'test_17'\n",
    "TEST_18_NAME = f'test_18'\n",
    "TRAIN_3000_NAME = f'train_3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = ''\n",
    "# SWAG_OUTPUT_DIR_PATH = '/home/unnc/Documents/_data/swag/' # Q C1 C2 C3 C4 C5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "# train_original_data = pd.read_excel(f'{ORIGIN_DIR_PATH}train.xlsx', header=None)\n",
    "test_original_data_17 = pd.read_excel(f'{ORIGIN_DIR_PATH}test_17-18.xlsx', sheet_name='2017', header=None)\n",
    "test_original_data_18 = pd.read_excel(f'{ORIGIN_DIR_PATH}test_17-18.xlsx', sheet_name='2018', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original_data_17.columns = ['q','c1','c2','c3','c4','c5','q_type','year', 'a']\n",
    "test_original_data_18.columns = ['q','c1','c2','c3','c4','c5','q_type','year', 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "OUTPUT_DIR_PATH = '/home/unnc/Desktop/snippet_type/_data/choice_all/' # QC1 QC2 QC3 QC4 QC5\n",
    "snippet_type = 'lvl_5_table'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_snippet_name_list():\n",
    "    col_name_list = []\n",
    "    for s in range(5):\n",
    "        for t in range(5):\n",
    "            col_name = f's{s}t{t}'\n",
    "            col_name_list.append(col_name)\n",
    "    return col_name_list\n",
    "\n",
    "def join_snippet(file_name):\n",
    "    snippet = {}\n",
    "    for i in range(5):\n",
    "        if file_name == 'test_17':\n",
    "            path = f'{SNIPPET_DIR_PATH}/2017真题查询结果/分答案搜索/{snippet_type}/{file_name}_{i+1}.xlsx'\n",
    "        if file_name == 'test_18':\n",
    "            path = f'{SNIPPET_DIR_PATH}/2018真题查询结果/分答案搜索/{snippet_type}/{file_name}_{i+1}.xlsx'\n",
    "        if file_name == 'train':\n",
    "            path = f'{SNIPPET_DIR_PATH}/训练集查询结果/分答案搜索/{snippet_type}/{file_name}_{i+1}.xlsx'\n",
    "        snippet[i] = pd.read_excel(path, header=None)\n",
    "        snippet[i].columns = _make_snippet_name_list()\n",
    "        index = np.arange(snippet[i].shape[0])*5 + i\n",
    "        snippet[i]['snippet_index'] = index \n",
    "    return snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snippet_test_17_dict = join_snippet('test_17')\n",
    "snippet_test_18_dict = join_snippet('test_18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single question\n",
    "\n",
    "$QC_1...C_5 \\longrightarrow \\sum_{c=1}^{5} QC_c$\n",
    "\n",
    "question + 5 choice -> 5 * (question + 1 choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_choices(df):\n",
    "    \"\"\"\n",
    "    return:\n",
    "    df with expanded choice\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    question_index = df.columns.get_loc('q')\n",
    "    first_choice_index = df.columns.get_loc('c1')\n",
    "    answer_index = df.columns.get_loc('a')\n",
    "    # iterate through all entries in df\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        one_entry = df.iloc[i,:] \n",
    "        # for each entry, take its 5 choices in sequence into 5 [question, one_choice, label] outputs\n",
    "        for choice_index in range(5):\n",
    "            label = 1 if (choice_index + 1)  == one_entry[answer_index] else 0\n",
    "            result.append({'q': one_entry[question_index], \n",
    "                       'c': one_entry[first_choice_index+choice_index],\n",
    "                       'q_type': one_entry['q_type'],\n",
    "                       'c_index': choice_index, \n",
    "                       'q_index': one_entry['q_index'],\n",
    "                       'a': label})\n",
    "    return pd.DataFrame(result)[['q','q_index','c','c_index','a','q_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_trunc_df(df_data):\n",
    "#     qst_list = combine_qst(df_data, True, True, True)\n",
    "#     df_trunc = df_data[['q','q_type','c1','c2','c3','c4','c5','a']].copy()\n",
    "#     df_trunc['q'] = qst_list\n",
    "#     return df_trunc\n",
    "def add_question_index(df_data):\n",
    "    question_len = df_data.shape[0]\n",
    "    df_data['q_index'] = range(question_len)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORRUPTED!! TRAINING FILE LENGTH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snippet_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "35507 - 2729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_original_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_expanded = expand_choices(add_question_index(test_original_data_17))\n",
    "test_17_expanded['snippet_index'] = range(test_17_expanded.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_18_expanded = expand_choices(add_question_index(test_original_data_18))\n",
    "test_18_expanded['snippet_index'] = range(test_18_expanded.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('17:', test_17_expanded.shape, '18:', test_18_expanded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_test_17 = pd.concat([snippet_test_17_dict[i] for i in range(5)]).sort_values(by=['snippet_index'])\n",
    "snippet_test_18 = pd.concat([snippet_test_18_dict[i] for i in range(5)]).sort_values(by=['snippet_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17 = pd.merge(test_17_expanded, snippet_test_17)\n",
    "test_18 = pd.merge(test_18_expanded, snippet_test_18)\n",
    "print('17:', test_17.shape, '18:', test_18.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop corruped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. handle corrupted row at 10040\n",
    "# if train_with_snippet[train_with_snippet.iloc[:,8].isnull() != True].iloc[:,0].tolist() != []:\n",
    "#     print(train_with_snippet[train_with_snippet.iloc[:,8].isnull() != True].iloc[:,0].tolist())\n",
    "#     train_with_snippet.drop(train_with_snippet.index[10040], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. handle wrong choice (longer than 400) at 21511\n",
    "# if len(train_with_snippet.iloc[21509,2]) > 400:\n",
    "#     print(train_with_snippet.iloc[21509,2])\n",
    "#     train_with_snippet.drop(train_with_snippet.index[21509], inplace=True)\n",
    "#     print('dropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop nan entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: question\n",
    "# 1: question type\n",
    "# 2-6: choices\n",
    "# 7: answer\n",
    "# 10: textbook snippet\n",
    "# 11-14: title level 1-4\n",
    "# train_data = train_with_snippet.iloc[:,[0,1,2,3,4,5,6,7,10,11,12,13,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_with_snippet.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_basic = ['snippet_index', 'q', 'q_type', 'c', 'a']\n",
    "col_list_sippet_best = ['s0t0','s0t1','s0t2','s0t3','s0t4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = col_list_basic + col_list_sippet_best\n",
    "test_17_data = test_17.loc[:,col_list]\n",
    "test_18_data = test_18.loc[:,col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop entries that has any nan and, \n",
    "# print num of nan in each col\n",
    "def any_nan_values(df):\n",
    "    return df.isnull().values.any()\n",
    "\n",
    "def drop_nan(df):\n",
    "    if any_nan_values(df):\n",
    "        print(\"nan in each col:\\n\", df.isnull().sum(), sep='')\n",
    "        \n",
    "        return df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = drop_nan(train_data)\n",
    "# reset index after dropping rows\n",
    "# train_data.reset_index(inplace=True)\n",
    "#train_data = train_data.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert every cell is not nan\n",
    "# assert not any_nan_values(train_data) \n",
    "assert not any_nan_values(test_17_data) and not any_nan_values(test_18_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.columns = ['q', 'q_type', 'c1', 'c2', 'c3', 'c4', 'c5', 'a', 's1', 's1t1', 's1t2', 's1t3', 's1t4']\n",
    "\n",
    "#test_17_data.columns = ['q','c1','c2','c3','c4','c5', 'q_type', 'year', 'a', 's1','s1t1','s1t2','s1t3','s1t4']\n",
    "#test_18_data.columns = ['q','c1','c2','c3','c4','c5', 'q_type', 'year', 'a', 's1','s1t1','s1t2','s1t3','s1t4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearange df columns to match the ones in training data\n",
    "# test_17_data = test_17_data[train_data.columns]\n",
    "# test_18_data = test_18_data[train_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw question len && snippet len graph \n",
    "# def draw_q_s_len(df):\n",
    "#     q_len = [len(str(i).replace(' ', '')) for i in df['q']]\n",
    "#     s1_len = [len(str(i).replace(' ', '')) for i in df['s0t0']]\n",
    "\n",
    "#     len_512 = round(sum([i > 512 for i in s1_len]) / len(s1_len), 2)\n",
    "#     len_756 = round(sum([i > 756 for i in s1_len]) / len(s1_len), 2)\n",
    "#     len_1024 = round(sum([i > 1024 for i in s1_len]) / len(s1_len), 2)\n",
    "\n",
    "#     label = f'snippet:   >512: {len_512}       >756: {len_756}      >1024: {len_1024}'\n",
    "\n",
    "#     a = sns.distplot(s1_len, kde=False, axlabel=label)\n",
    "#     a = sns.distplot(q_len, kde=False)\n",
    "#     a = a.get_figure()\n",
    "#     a.savefig(f'/{TRUNC_OUTPUT_DIR_PATH}/{output_dir}/qs.png', dpi=120, bbox_inches='tight')\n",
    "#     print('saved to:', TRUNC_OUTPUT_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_q_s_len(test_17_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add textbook snippit - only the best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _combine_titles(df_titles):\n",
    "    \"\"\"\n",
    "    df_titles: any cleaned df that contains title information \n",
    "    \n",
    "    return: list\n",
    "    \"\"\"\n",
    "    return [' '.join(titles) for titles in df_titles[['s0t1', 's0t2', 's0t3', 's0t4']].values]\n",
    "\n",
    "\n",
    "def combine_qst(df_data, add_q=True, add_s=True, add_t=True):\n",
    "    \"\"\"\n",
    "    return: list\n",
    "    \n",
    "    output sequence is [title + question + snippet]\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if add_t:\n",
    "        t = _combine_titles(df_data)\n",
    "    q = df_data['q'].values\n",
    "    s1 = df_data['s0t0'].values\n",
    "    \n",
    "    for i in range(df_data.shape[0]):\n",
    "        assert 'æ' not in t[i] and 'æ' not in q[i] and 'æ' not in s1[i], 'Input data contains æ sign'\n",
    "        all_tqs = [t[i], q[i], s1[i]] # change output sequence here\n",
    "        input_tqs = [] \n",
    "        for i, add in enumerate([add_t, add_q, add_s]): # should be the same sequence as all_tqs\n",
    "            if add:\n",
    "                input_tqs.append(all_tqs[i])\n",
    "        input_row = '  æ  '.join(input_tqs)\n",
    "        result.append(input_row)\n",
    "    print(f'First output is \\n{result[0]}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trunc_df(df_data):\n",
    "    qst_list = combine_qst(df_data, True, True, True)\n",
    "    df_trunc = df_data.copy()\n",
    "    df_trunc['input'] = qst_list\n",
    "    return df_trunc\n",
    "# def add_question_index(df_data):\n",
    "#     question_len = df_data.shape[0]\n",
    "#     df_data['q_index'] = range(question_len)\n",
    "#     return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_trunc = get_trunc_df(train_data)\n",
    "# train_trunc = add_question_index(train_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_trunc = get_trunc_df(test_17_data)\n",
    "# test_17_trunc = add_question_index(test_17_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_18_trunc = get_trunc_df(test_18_data)\n",
    "# test_18_trunc = add_question_index(test_18_trunc)\n",
    "assert test_18_trunc.shape[0] == 2995 and test_17_trunc.shape[0] == 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_input_len(df):\n",
    "    input_len = [len(i.replace(' ', '')) for i in df['input']]\n",
    "    len_512 = round(sum([i > 512 for i in input_len]) / len(input_len), 2)\n",
    "    len_756 = round(sum([i > 756 for i in input_len]) / len(input_len), 2)\n",
    "    len_1024 = round(sum([i > 1024 for i in input_len]) / len(input_len), 2)\n",
    "\n",
    "    label = f'test_17: >512: {len_512}       >756: {len_756}      >1024: {len_1024}'\n",
    "    a = sns.distplot(input_len, kde=False, axlabel=label)\n",
    "    a = a.get_figure()\n",
    "    a.savefig(f'/{OUTPUT_DIR_PATH}/{snippet_type}/test_17_len.png', dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_input_len(test_17_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def shuffle_df(df, frac=1, random_state=42):\n",
    "#     return df.sample(frac=frac, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_trunc_shuffled = shuffle_df(train_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_trunc_shuffled.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_trunc_df = expand_choices(train_trunc_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files to help calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_debug_file(df, file_name):\n",
    "#     df.to_excel(f'{TRUNC_OUTPUT_DIR_PATH}/{output_dir}/{file_name}_debug.xlsx', index=None)\n",
    "#     print(f'{file_name} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_debug_file(test_17_trunc_df, TEST_17_NAME)\n",
    "# save_debug_file(test_18_trunc_df, TEST_18_NAME)\n",
    "# save_debug_file(train_trunc_df.head(15000), TRAIN_3000_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_bert(df):\n",
    "    return pd.DataFrame({\n",
    "        'id':range(df.shape[0]),\n",
    "        'label':df['a'],\n",
    "        'alpha':['a']*df.shape[0],\n",
    "        'text_a': df['input'].replace(r'\\n', ' ', regex=True),\n",
    "        'text_b': df['c'].replace(r'\\n', ' ', regex=True)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_18_trunc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_trunc_bert = prepare_for_bert(train_trunc_df)\n",
    "\n",
    "test_17_trunc_bert = prepare_for_bert(test_17_trunc)\n",
    "test_18_trunc_bert = prepare_for_bert(test_18_trunc)\n",
    "# train_3000_trunc_bert = prepare_for_bert(train_trunc_df.head(15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert diff choices have diff input (snippet) for a same question\n",
    "assert test_17_trunc_bert.head(5)['text_a'][1] != test_17_trunc_bert.head(5)['text_a'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_input_file(df_bert, file_name):\n",
    "    df_bert.to_csv(f'{OUTPUT_DIR_PATH}/{snippet_type}/{file_name}.tsv', \n",
    "                sep='\\t', index=False, header=False)\n",
    "    print(f'{file_name} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_input_file(train_trunc_bert, TRAIN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_input_file(test_17_trunc_bert, TEST_17_NAME)\n",
    "save_input_file(test_18_trunc_bert, TEST_18_NAME)\n",
    "# save_input_file(train_3000_trunc_bert, TRAIN_3000_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{OUTPUT_DIR_PATH}/{snippet_type}/{TEST_17_NAME}.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
