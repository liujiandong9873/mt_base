{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNIPPET_DIR_PATH = '/home/unnc/Documents/_data/_snippet/'\n",
    "ORIGIN_DIR_PATH = '/home/unnc/Documents/_data/_original_data/'\n",
    "\n",
    "\n",
    "TRAIN_NAME = f'train'\n",
    "\n",
    "TEST_17_NAME = f'test_17'\n",
    "TEST_18_NAME = f'test_18'\n",
    "TRAIN_3000_NAME = f'train_3000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUNC_OUTPUT_DIR_PATH = '/home/unnc/Desktop/trunc/' # QC1 QC2 QC3 QC4 QC5\n",
    "# SWAG_OUTPUT_DIR_PATH = '/home/unnc/Documents/_data/swag/' # Q C1 C2 C3 C4 C5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "train_original_data = pd.read_excel(f'{ORIGIN_DIR_PATH}train.xlsx', header=None)\n",
    "test_original_data_17 = pd.read_excel(f'{ORIGIN_DIR_PATH}test_17-18.xlsx', sheet_name='2017', header=None)\n",
    "test_original_data_18 = pd.read_excel(f'{ORIGIN_DIR_PATH}test_17-18.xlsx', sheet_name='2018', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 5_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_type = '5_3'\n",
    "output_dir = f'lvl_{snippet_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snippet \n",
    "snippet_train = pd.read_excel(f'{SNIPPET_DIR_PATH}/训练集查询结果/带答案搜索/level{snippet_type}.xlsx', header=None)\n",
    "snippet_test_17 = pd.read_excel(f'{SNIPPET_DIR_PATH}/2017真题查询结果/带答案搜索/indexLevels{snippet_type}.xlsx', header=None)\n",
    "snippet_test_18 = pd.read_excel(f'{SNIPPET_DIR_PATH}/2018真题查询结果/带答案搜索/indexLevels{snippet_type}.xlsx', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate orginal data with snippet\n",
    "train_with_snippet = pd.concat([train_original_data, snippet_train], axis=1)\n",
    "test_17_all = pd.concat([test_original_data_17, snippet_test_17], axis=1)\n",
    "test_18_all = pd.concat([test_original_data_18, snippet_test_18], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop corruped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. handle corrupted row at 10040\n",
    "if train_with_snippet[train_with_snippet.iloc[:,8].isnull() != True].iloc[:,0].tolist() != []:\n",
    "    print(train_with_snippet[train_with_snippet.iloc[:,8].isnull() != True].iloc[:,0].tolist())\n",
    "    train_with_snippet.drop(train_with_snippet.index[10040], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. handle wrong choice (longer than 400) at 21511\n",
    "if len(train_with_snippet.iloc[21509,2]) > 400:\n",
    "    print(train_with_snippet.iloc[21509,2])\n",
    "    train_with_snippet.drop(train_with_snippet.index[21509], inplace=True)\n",
    "    print('dropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop nan entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: question\n",
    "# 1: question type\n",
    "# 2-6: choices\n",
    "# 7: answer\n",
    "# 10: textbook snippet\n",
    "# 11-14: title level 1-4\n",
    "train_data = train_with_snippet.iloc[:,[0,1,2,3,4,5,6,7,10,11,12,13,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_snippet.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: question\n",
    "# 1: question type\n",
    "# 2-6: choices\n",
    "# 7: answer\n",
    "# 8: textbook snippet: best\n",
    "# 9-14: title level 1-4\n",
    "test_17_data = test_17_all.iloc[:,[0,1,2,3,4,5,6,7, 8, 9,10,11,12,13]]\n",
    "test_18_data = test_18_all.iloc[:,[0,1,2,3,4,5,6,7, 8, 9,10,11,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop entries that has any nan and, \n",
    "# print num of nan in each col\n",
    "def any_nan_values(df):\n",
    "    return df.isnull().values.any()\n",
    "\n",
    "def drop_nan(df):\n",
    "    if any_nan_values(df):\n",
    "        print(\"nan in each col:\\n\", df.isnull().sum(), sep='')\n",
    "        \n",
    "        return df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = drop_nan(train_data)\n",
    "# reset index after dropping rows\n",
    "train_data.reset_index(inplace=True)\n",
    "train_data = train_data.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert every cell is not nan\n",
    "assert not any_nan_values(train_data) and not any_nan_values(test_17_data) and not any_nan_values(test_18_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = ['q', 'q_type', 'c1', 'c2', 'c3', 'c4', 'c5', 'a', 's1', 's1t1', 's1t2', 's1t3', 's1t4']\n",
    "\n",
    "test_17_data.columns = ['q','c1','c2','c3','c4','c5', 'q_type', 'year', 'a', 's1','s1t1','s1t2','s1t3','s1t4']\n",
    "test_18_data.columns = ['q','c1','c2','c3','c4','c5', 'q_type', 'year', 'a', 's1','s1t1','s1t2','s1t3','s1t4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearange df columns to match the ones in training data\n",
    "test_17_data = test_17_data[train_data.columns]\n",
    "test_18_data = test_18_data[train_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw question len && snippet len graph \n",
    "def draw_q_s_len(df):\n",
    "    q_len = [len(str(i).replace(' ', '')) for i in df['q']]\n",
    "    s1_len = [len(str(i).replace(' ', '')) for i in df['s1']]\n",
    "\n",
    "    len_512 = round(sum([i > 512 for i in s1_len]) / len(s1_len), 2)\n",
    "    len_756 = round(sum([i > 756 for i in s1_len]) / len(s1_len), 2)\n",
    "    len_1024 = round(sum([i > 1024 for i in s1_len]) / len(s1_len), 2)\n",
    "\n",
    "    label = f'snippet:   >512: {len_512}       >756: {len_756}      >1024: {len_1024}'\n",
    "\n",
    "    a = sns.distplot(s1_len, kde=False, axlabel=label)\n",
    "    a = sns.distplot(q_len, kde=False)\n",
    "    a = a.get_figure()\n",
    "    a.savefig(f'/{TRUNC_OUTPUT_DIR_PATH}/{output_dir}/qs.png', dpi=120, bbox_inches='tight')\n",
    "    print('saved to:', TRUNC_OUTPUT_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_q_s_len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add textbook snippit - only the best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_titles(df_titles):\n",
    "    \"\"\"\n",
    "    df_titles: any cleaned df that contains title information \n",
    "    \n",
    "    return: list\n",
    "    \"\"\"\n",
    "    return [' '.join(titles) for titles in df_titles[['s1t1', 's1t2', 's1t3', 's1t4']].values]\n",
    "\n",
    "\n",
    "def combine_qst(df_data, add_q=True, add_s=True, add_t=True):\n",
    "    \"\"\"\n",
    "    return: list\n",
    "    \n",
    "    output sequence is [title + question + snippet]\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    if add_t:\n",
    "        t = combine_titles(df_data)\n",
    "    q = df_data['q'].values\n",
    "    s1 = df_data['s1'].values\n",
    "    \n",
    "    for i in range(df_data.shape[0]):\n",
    "        assert 'æ' not in t[i] and 'æ' not in q[i] and 'æ' not in s1[i], 'Input data contains æ sign'\n",
    "        all_tqs = [t[i], q[i], s1[i]] # change output sequence here\n",
    "        input_tqs = [] \n",
    "        for i, add in enumerate([add_t, add_q, add_s]): # should be the same sequence as all_tqs\n",
    "            if add:\n",
    "                input_tqs.append(all_tqs[i])\n",
    "        input_row = '  æ  '.join(input_tqs)\n",
    "        result.append(input_row)\n",
    "    print(f'First output is \\n{result[0]}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trunc_df(df_data):\n",
    "    qst_list = combine_qst(df_data, True, True, True)\n",
    "    df_trunc = df_data[['q','q_type','c1','c2','c3','c4','c5','a']].copy()\n",
    "    df_trunc['q'] = qst_list\n",
    "    return df_trunc\n",
    "def add_question_index(df_data):\n",
    "    question_len = df_data.shape[0]\n",
    "    df_data['q_index'] = range(question_len)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trunc = get_trunc_df(train_data)\n",
    "train_trunc = add_question_index(train_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_trunc = get_trunc_df(test_17_data)\n",
    "test_17_trunc = add_question_index(test_17_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_18_trunc = get_trunc_df(test_18_data)\n",
    "test_18_trunc = add_question_index(test_18_trunc)\n",
    "assert test_18_trunc.shape[0] == 599 and test_17_trunc.shape[0] == 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_input_len(df):\n",
    "    input_len = [len(i.replace(' ', '')) for i in df['q']]\n",
    "    len_512 = round(sum([i > 512 for i in input_len]) / len(input_len), 2)\n",
    "    len_756 = round(sum([i > 756 for i in input_len]) / len(input_len), 2)\n",
    "    len_1024 = round(sum([i > 1024 for i in input_len]) / len(input_len), 2)\n",
    "\n",
    "    label = f'>512: {len_512}       >756: {len_756}      >1024: {len_1024}'\n",
    "    a = sns.distplot(input_len, kde=False, axlabel=label)\n",
    "    a = a.get_figure()\n",
    "    a.savefig(f'/{TRUNC_OUTPUT_DIR_PATH}/{output_dir}/input_len.png', dpi=120, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_input_len(train_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_df(df, frac=1, random_state=42):\n",
    "    return df.sample(frac=frac, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trunc_shuffled = shuffle_df(train_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trunc_shuffled.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TRUNC method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single question\n",
    "\n",
    "$QC_1...C_5 \\longrightarrow \\sum_{c=1}^{5} QC_c$\n",
    "\n",
    "question + 5 choice -> 5 * (question + 1 choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_choices(df):\n",
    "    \"\"\"\n",
    "    return:\n",
    "    df with expanded choice\n",
    "    \"\"\"\n",
    "    \n",
    "    result = []\n",
    "    question_index = df.columns.get_loc('q')\n",
    "    first_choice_index = df.columns.get_loc('c1')\n",
    "    answer_index = df.columns.get_loc('a')\n",
    "    # iterate through all entries in df\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        one_entry = df.iloc[i,:] \n",
    "        # for each entry, take its 5 choices in sequence into 5 [question, one_choice, label] outputs\n",
    "        for choice_index in range(5):\n",
    "            label = 1 if (choice_index + 1)  == one_entry[answer_index] else 0\n",
    "            result.append({'input': one_entry[question_index], \n",
    "                       'choice': one_entry[first_choice_index+choice_index],\n",
    "                       'q_type': one_entry['q_type'],\n",
    "                       'c_index': choice_index, \n",
    "                       'q_index': one_entry['q_index'],\n",
    "                       'label': label})\n",
    "    return pd.DataFrame(result)[['input','q_index','choice','c_index','label','q_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trunc_df = expand_choices(train_trunc_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_17_trunc_df = expand_choices(test_17_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_18_trunc_df = expand_choices(test_18_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files to help calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_debug_file(df, file_name):\n",
    "    df.to_excel(f'{TRUNC_OUTPUT_DIR_PATH}/{output_dir}/{file_name}_debug.xlsx', index=None)\n",
    "    print(f'{file_name} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_debug_file(test_17_trunc_df, TEST_17_NAME)\n",
    "save_debug_file(test_18_trunc_df, TEST_18_NAME)\n",
    "save_debug_file(train_trunc_df.head(15000), TRAIN_3000_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_bert(df):\n",
    "    return pd.DataFrame({\n",
    "        'id':range(df.shape[0]),\n",
    "        'label':df['label'],\n",
    "        'alpha':['a']*df.shape[0],\n",
    "        'text_a': df['input'].replace(r'\\n', ' ', regex=True),\n",
    "        'text_b': df['choice'].replace(r'\\n', ' ', regex=True)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trunc_bert = prepare_for_bert(train_trunc_df)\n",
    "\n",
    "test_17_trunc_bert = prepare_for_bert(test_17_trunc_df)\n",
    "test_18_trunc_bert = prepare_for_bert(test_18_trunc_df)\n",
    "train_3000_trunc_bert = prepare_for_bert(train_trunc_df.head(15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_input_file(df_bert, file_name):\n",
    "    df_bert.to_csv(f'{TRUNC_OUTPUT_DIR_PATH}/{output_dir}/{file_name}.tsv', \n",
    "                sep='\\t', index=False, header=False)\n",
    "    print(f'{file_name} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_input_file(train_trunc_bert, TRAIN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_input_file(test_17_trunc_bert, TEST_17_NAME)\n",
    "save_input_file(test_18_trunc_bert, TEST_18_NAME)\n",
    "save_input_file(train_3000_trunc_bert, TRAIN_3000_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
